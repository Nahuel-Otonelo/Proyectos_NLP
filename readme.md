# üì∞ Proyecto 1: Clasificaci√≥n de Texto con Naive Bayes (Dataset 20 Newsgroups)

Este proyecto es el primer desaf√≠o de la mater√≠a Procesamiento de Lenguaje Natural (PLN).

El notebook `Desafio_1.ipynb` explora la vectorizaci√≥n de texto (TF-IDF), la similaridad de documentos, la implementaci√≥n de clasificadores (k-NN y Naive Bayes) y la optimizaci√≥n de hiperpar√°metros.

## üìä Dataset

Se utiliz√≥ el dataset **20 Newsgroups**, cargado directamente desde `scikit-learn`. Este es un conjunto cl√°sico para la clasificaci√≥n de texto, compuesto por ~18,000 mensajes de foros distribuidos en 20 categor√≠as tem√°ticas (ej. `rec.autos`, `sci.med`, `talk.politics.misc`).

---

## üõ†Ô∏è Desaf√≠os y Metodolog√≠a

El notebook est√° dividido en los 4 puntos de la consigna:

### 1. An√°lisis de Similaridad de Documentos

Se vectoriz√≥ el corpus de `train` con `TfidfVectorizer`. Luego, se midi√≥ la similaridad coseno entre 5 documentos elegidos al azar y el resto del corpus para analizar la coherencia de las clases de los documentos m√°s similares.

### 2. Clasificador por Prototipos (k-NN)

Se construy√≥ un clasificador 1-NN ("prototipo") asignando la clase del vecino m√°s cercano. Como extensi√≥n, se implement√≥ un clasificador **k-NN** completo, probando un rango de $k$ (de 1 a 21) y comparando dos estrategias de votaci√≥n:

* **Voto Democr√°tico (`weights='uniform'`)**
* **Voto Calificado (`weights='distance'`)**

Se gener√≥ un gr√°fico para comparar el F1-Score de ambas estrategias y encontrar el $k$ √≥ptimo.

### 3. Optimizaci√≥n de Naive Bayes (GridSearch)

El objetivo era maximizar el `f1-score (macro)`:

1.  Se compar√≥ `MultinomialNB` vs. `ComplementNB`, identificando a `ComplementNB` como el modelo superior (probablemente por el desbalance de clases del dataset).
2.  Se implement√≥ un **`Pipeline`** de `scikit-learn` para encadenar el `TfidfVectorizer` y el `ComplementNB`.
3.  Se utiliz√≥ **`GridSearchCV`** para encontrar la mejor combinaci√≥n de hiperpar√°metros, previniendo el *data leakage* mediante validaci√≥n cruzada.

### 4. Similaridad de Palabras (Matriz Transpuesta)

Finalmente, se transpuso la matriz TF-IDF (documento-t√©rmino) para obtener una matriz (t√©rmino-documento).

* Cada fila se reinterpret√≥ como un **vector de palabra** (un embedding simple).
* Se analiz√≥ la similaridad coseno de 5 palabras (`god`, `car`, `president`, etc.) para estudiar las relaciones sem√°nticas y de co-ocurrencia que el modelo fue capaz de capturar.

---

# üí¨ Desaf√≠o 2: Embeddings de Palabras con Word2Vec (Mart√≠n Fierro)

Este proyecto es el segundo desaf√≠o de la **materia**, enfocado en la creaci√≥n y an√°lisis de embeddings de palabras personalizados.

El notebook `Desafio_2.ipynb` implementa la librer√≠a `Gensim` para entrenar un modelo **Word2Vec (Skip-gram)**, utilizando un corpus de texto en espa√±ol.

## üìñ Dataset

Se utiliz√≥ un corpus personalizado compuesto por las dos obras de Jos√© Hern√°ndez: **"El Gaucho Mart√≠n Fierro"** y **"La Vuelta de Mart√≠n Fierro"**.

Los textos se obtuvieron del sitio `textos.info` en formato `.epub`, se convirtieron a `.txt` con una herramienta online y se limpiaron manualmente para retener √∫nicamente los versos del poema.

## üõ†Ô∏è Desaf√≠os y Metodolog√≠a

### 1. Preprocesamiento del Corpus con NLTK

A diferencia del desaf√≠o anterior, se utiliz√≥ un enfoque verso por verso (l√≠nea por l√≠nea). El preprocesamiento se realiz√≥ con `NLTK`, incluyendo:

* **Tokenizaci√≥n:** `nltk.word_tokenize` para cada verso.
* **Filtrado de Stop Words:** Se eliminaron las palabras vac√≠as del espa√±ol (ej. "de", "la", "que") utilizando el corpus `stopwords` de NLTK.
* **Limpieza:** Se filtraron signos de puntuaci√≥n y n√∫meros usando `.isalpha()`.

### 2. Entrenamiento de Word2Vec (Gensim)

Se ajustaron los hiperpar√°metros del modelo `Word2Vec` a un corpus relativamente peque√±o (1375 palabras de vocabulario √∫nicas despu√©s del filtrado).

### 3. An√°lisis de Similaridad Sem√°ntica

Se utiliz√≥ el m√©todo `w2v_model.wv.most_similar` para consultar el modelo entrenado y analizar la coherencia sem√°ntica de los vectores generados, tanto para palabras similares como no relacionadas.

### 4. Visualizaci√≥n y Clustering (t-SNE)

Se realiz√≥ una reducci√≥n de dimensionalidad para poder graficar en dos dimensiones las palabras. Luego se interpretaron algunos **de los** resultados:

1.  Se utiliz√≥ **t-SNE** (`sklearn.manifold.TSNE`) para "aplastar" los vectores de 100 dimensiones a un espacio 2D.
2.  Se gener√≥ un gr√°fico interactivo con `Plotly Express` para visualizar las 800 palabras m√°s frecuentes.
3.  Se inspeccion√≥ el gr√°fico para **identificar y analizar clusters sem√°nticos**. Interpretaciones destacadas: