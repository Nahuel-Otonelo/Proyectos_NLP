# üì∞ Proyecto 1: Clasificaci√≥n de Texto con Naive Bayes (Dataset 20 Newsgroups)

Este proyecto es el primer desaf√≠o de la mater√≠a Procesamiento de Lenguaje Natural (PLN). 

El notebook `Desafio_1.ipynb` explora la vectorizaci√≥n de texto (TF-IDF), la similaridad de documentos, la implementaci√≥n de clasificadores (k-NN y Naive Bayes) y la optimizaci√≥n de hiperpar√°metros.

## üìä Dataset

Se utiliz√≥ el dataset **20 Newsgroups**, cargado directamente desde `scikit-learn`. Este es un conjunto cl√°sico para la clasificaci√≥n de texto, compuesto por ~18,000 mensajes de foros distribuidos en 20 categor√≠as tem√°ticas (ej. `rec.autos`, `sci.med`, `talk.politics.misc`).


---

## üõ†Ô∏è Desaf√≠os y Metodolog√≠a

El notebook est√° dividido en los 4 puntos de la consigna:

### 1. An√°lisis de Similaridad de Documentos
Se vectoriz√≥ el corpus de `train` con `TfidfVectorizer`. Luego, se midi√≥ la similaridad coseno entre 5 documentos elegidos al azar y el resto del corpus para analizar la coherencia de las clases de los documentos m√°s similares.

### 2. Clasificador por Prototipos (k-NN)
Se construy√≥ un clasificador 1-NN ("prototipo") asignando la clase del vecino m√°s cercano. Como extensi√≥n, se implement√≥ un clasificador **k-NN** completo, probando un rango de $k$ (de 1 a 21) y comparando dos estrategias de votaci√≥n:
* **Voto Democr√°tico (`weights='uniform'`)**
* **Voto Calificado (`weights='distance'`)**

Se gener√≥ un gr√°fico para comparar el F1-Score de ambas estrategias y encontrar el $k$ √≥ptimo.

### 3. Optimizaci√≥n de Naive Bayes (GridSearch)
El objetivo era maximizar el `f1-score (macro)`:
1.  Se compar√≥ `MultinomialNB` vs. `ComplementNB`, identificando a `ComplementNB` como el modelo superior (probablemente por el desbalance de clases del dataset).
2.  Se implement√≥ un **`Pipeline`** de `scikit-learn` para encadenar el `TfidfVectorizer` y el `ComplementNB`.
3.  Se utiliz√≥ **`GridSearchCV`** para encontrar la mejor combinaci√≥n de hiperpar√°metros, previniendo el *data leakage* mediante validaci√≥n cruzada.

### 4. Similaridad de Palabras (Matriz Transpuesta)
Finalmente, se transpuso la matriz TF-IDF (documento-t√©rmino) para obtener una matriz (t√©rmino-documento).
* Cada fila se reinterpret√≥ como un **vector de palabra** (un embedding simple).
* Se analiz√≥ la similaridad coseno de 5 palabras (`god`, `car`, `president`, etc.) para estudiar las relaciones sem√°nticas y de co-ocurrencia que el modelo fue capaz de capturar.

